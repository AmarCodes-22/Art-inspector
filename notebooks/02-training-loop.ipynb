{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.cifar100 import Cifar100\n",
    "from src.models.baseline import Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'aquatic_mammals': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc6d0>,\n",
      "                                 'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc5e0>},\n",
      "             'fish': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9070>,\n",
      "                      'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dcf40>},\n",
      "             'flowers': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dcc70>,\n",
      "                         'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dcb80>},\n",
      "             'food_containers': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9610>,\n",
      "                                 'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9520>},\n",
      "             'fruit_and_vegetables': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc310>,\n",
      "                                      'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc1c0>},\n",
      "             'household_electrical_devices': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f99d0>,\n",
      "                                              'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f98e0>},\n",
      "             'household_furniture': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c550>,\n",
      "                                     'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c460>},\n",
      "             'insects': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc8b0>,\n",
      "                         'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc7c0>},\n",
      "             'large_carnivores': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c370>,\n",
      "                                  'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c280>},\n",
      "             'large_man-made_outdoor_things': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f97f0>,\n",
      "                                               'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9700>},\n",
      "             'large_natural_outdoor_scenes': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c190>,\n",
      "                                              'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe79477c0a0>},\n",
      "             'large_omnivores_and_herbivores': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9430>,\n",
      "                                                'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9340>},\n",
      "             'medium_mammals': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9d90>,\n",
      "                                'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9ca0>},\n",
      "             'non-insect_invertebrates': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9250>,\n",
      "                                          'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9160>},\n",
      "             'people': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc040>,\n",
      "                        'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7e82e8310>},\n",
      "             'reptiles': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dca90>,\n",
      "                          'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc9a0>},\n",
      "             'small_mammals': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dce50>,\n",
      "                               'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dcd60>},\n",
      "             'trees': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc4f0>,\n",
      "                       'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7948dc400>},\n",
      "             'vehicles_1': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9f70>,\n",
      "                            'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9e80>},\n",
      "             'vehicles_2': {'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9bb0>,\n",
      "                            'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7947f9ac0>}})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# load cifar100\n",
    "def load_cifar100():\n",
    "    cifar100 = Cifar100()\n",
    "    dataloaders = cifar100.load_branch_dataloaders()\n",
    "    return dataloaders\n",
    "\n",
    "cifar_branch_dataloaders = load_cifar100()\n",
    "pprint(cifar_branch_dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing model summary\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "Baseline                                           --                        --\n",
      "├─Stem: 1-1                                        [16, 512]                 --\n",
      "│    └─ResNet: 2-1                                 [16, 512]                 --\n",
      "│    │    └─Conv2d: 3-1                            [16, 64, 16, 16]          9,408\n",
      "│    │    └─BatchNorm2d: 3-2                       [16, 64, 16, 16]          128\n",
      "│    │    └─ReLU: 3-3                              [16, 64, 16, 16]          --\n",
      "│    │    └─MaxPool2d: 3-4                         [16, 64, 8, 8]            --\n",
      "│    │    └─Sequential: 3-5                        [16, 64, 8, 8]            73,984\n",
      "│    │    └─Sequential: 3-6                        [16, 128, 4, 4]           230,144\n",
      "│    │    └─Sequential: 3-7                        [16, 256, 2, 2]           919,040\n",
      "│    │    └─Sequential: 3-8                        [16, 512, 1, 1]           3,673,088\n",
      "│    │    └─AdaptiveAvgPool2d: 3-9                 [16, 512, 1, 1]           --\n",
      "│    │    └─Identity: 3-10                         [16, 512]                 --\n",
      "├─Branch: 1-2                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-2                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-11                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-12                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-13                           [16, 5]                   1,285\n",
      "├─Branch: 1-3                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-3                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-14                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-15                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-16                           [16, 5]                   1,285\n",
      "├─Branch: 1-4                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-4                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-17                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-18                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-19                           [16, 5]                   1,285\n",
      "├─Branch: 1-5                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-5                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-20                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-21                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-22                           [16, 5]                   1,285\n",
      "├─Branch: 1-6                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-6                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-23                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-24                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-25                           [16, 5]                   1,285\n",
      "├─Branch: 1-7                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-7                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-26                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-27                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-28                           [16, 5]                   1,285\n",
      "├─Branch: 1-8                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-8                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-29                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-30                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-31                           [16, 5]                   1,285\n",
      "├─Branch: 1-9                                      [16, 5]                   --\n",
      "│    └─Sequential: 2-9                             [16, 5]                   --\n",
      "│    │    └─Linear: 3-32                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-33                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-34                           [16, 5]                   1,285\n",
      "├─Branch: 1-10                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-10                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-35                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-36                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-37                           [16, 5]                   1,285\n",
      "├─Branch: 1-11                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-11                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-38                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-39                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-40                           [16, 5]                   1,285\n",
      "├─Branch: 1-12                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-12                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-41                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-42                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-43                           [16, 5]                   1,285\n",
      "├─Branch: 1-13                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-13                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-44                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-45                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-46                           [16, 5]                   1,285\n",
      "├─Branch: 1-14                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-14                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-47                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-48                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-49                           [16, 5]                   1,285\n",
      "├─Branch: 1-15                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-15                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-50                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-51                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-52                           [16, 5]                   1,285\n",
      "├─Branch: 1-16                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-16                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-53                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-54                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-55                           [16, 5]                   1,285\n",
      "├─Branch: 1-17                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-17                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-56                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-57                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-58                           [16, 5]                   1,285\n",
      "├─Branch: 1-18                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-18                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-59                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-60                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-61                           [16, 5]                   1,285\n",
      "├─Branch: 1-19                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-19                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-62                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-63                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-64                           [16, 5]                   1,285\n",
      "├─Branch: 1-20                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-20                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-65                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-66                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-67                           [16, 5]                   1,285\n",
      "├─Branch: 1-21                                     [16, 5]                   --\n",
      "│    └─Sequential: 2-21                            [16, 5]                   --\n",
      "│    │    └─Linear: 3-68                           [16, 256]                 131,328\n",
      "│    │    └─ReLU: 3-69                             [16, 256]                 --\n",
      "│    │    └─Linear: 3-70                           [16, 5]                   1,285\n",
      "====================================================================================================\n",
      "Total params: 7,558,052\n",
      "Trainable params: 7,558,052\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 332.72\n",
      "====================================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 9.71\n",
      "Params size (MB): 30.23\n",
      "Estimated Total Size (MB): 40.14\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# load baseline model\n",
    "def load_baseline(branch_dataloaders: dict):\n",
    "    resnet_layers = [1,1,1,1]\n",
    "    model = Baseline(stem_layers=resnet_layers)\n",
    "\n",
    "    stem_out_size = model.stem.get_output_size(input_size=(16, 3, 32, 32))\n",
    "\n",
    "    branch_configs = dict()\n",
    "    for branch_name, branch_dataloader in branch_dataloaders.items():\n",
    "        branch_configs[branch_name] = tuple(\n",
    "            (stem_out_size, len(branch_dataloader['train'].dataset.classes))\n",
    "        )\n",
    "\n",
    "    model.initialize_branches(branch_configs=branch_configs)\n",
    "    return model\n",
    "\n",
    "baseline = load_baseline(branch_dataloaders=cifar_branch_dataloaders)\n",
    "baseline.print_model_summary(input_size=(16, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataloaders for branch: people\n",
      "Features shape: torch.Size([16, 3, 32, 32])\n",
      "Labels shape: torch.Size([16])\n",
      "Output shape from single branch: torch.Size([16, 5])\n",
      "Output shape from all branches: torch.Size([16, 100])\n"
     ]
    }
   ],
   "source": [
    "# implement a forward pass through the baseline\n",
    "for branch_name, branch_dataloaders in cifar_branch_dataloaders.items():\n",
    "    print(f'Loaded dataloaders for branch: {branch_name}')\n",
    "\n",
    "    train_features, train_labels = next(iter(branch_dataloaders['train']))\n",
    "    \n",
    "    print(f'Features shape: {train_features.shape}')\n",
    "    print(f'Labels shape: {train_labels.shape}')\n",
    "\n",
    "    # get output from a single branch\n",
    "    out = baseline(train_features, branch_name)\n",
    "    print(f'Output shape from single branch: {out.shape}')\n",
    "\n",
    "    # get output from all branches\n",
    "    out = baseline(train_features)\n",
    "    print(f'Output shape from all branches: {out.shape}')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 20\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe7e82e8310>\n"
     ]
    }
   ],
   "source": [
    "branches = list(cifar_branch_dataloaders.keys())\n",
    "\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "for branch in branches:\n",
    "    train_test_dataloaders = cifar_branch_dataloaders[branch]\n",
    "\n",
    "    train_loader = train_test_dataloaders['train']\n",
    "    test_loader = train_test_dataloaders['test']\n",
    "\n",
    "    # train_loaders.append((branch, train_loader))\n",
    "    # test_loaders.append((branch, test_loader))\n",
    "    train_loaders.append(train_loader)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "print(type(train_loaders), len(train_loaders))\n",
    "print(train_loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, data in enumerate(zip(*train_loaders)):\n",
    "    for branch_name, branch_batch in zip(branches, data):\n",
    "        print(branch_name)\n",
    "\n",
    "        images, labels = branch_batch\n",
    "        img = images[0].cpu().detach().numpy()\n",
    "        img = np.moveaxis(img, 0, -1)\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        break\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(baseline.parameters(), lr=0.0005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1, Loss: 32.759\n",
      "Epoch: 1, Batch: 2, Loss: 32.187\n",
      "Epoch: 1, Batch: 3, Loss: 32.424\n",
      "Epoch: 1, Batch: 4, Loss: 32.574\n",
      "Epoch: 1, Batch: 5, Loss: 32.489\n",
      "Epoch: 1, Batch: 6, Loss: 32.268\n",
      "Epoch: 1, Batch: 7, Loss: 32.166\n",
      "Epoch: 1, Batch: 8, Loss: 32.555\n",
      "Epoch: 1, Batch: 9, Loss: 32.083\n",
      "Epoch: 1, Batch: 10, Loss: 32.509\n",
      "Epoch: 1, Batch: 11, Loss: 31.825\n",
      "Epoch: 1, Batch: 12, Loss: 31.997\n",
      "Epoch: 1, Batch: 13, Loss: 32.127\n",
      "Epoch: 1, Batch: 14, Loss: 31.508\n",
      "Epoch: 1, Batch: 15, Loss: 31.659\n",
      "Epoch: 1, Batch: 16, Loss: 31.318\n",
      "Epoch: 1, Batch: 17, Loss: 31.442\n",
      "Epoch: 1, Batch: 18, Loss: 31.541\n",
      "Epoch: 1, Batch: 19, Loss: 31.453\n",
      "Epoch: 1, Batch: 20, Loss: 31.335\n",
      "Epoch: 1, Batch: 21, Loss: 31.562\n",
      "Epoch: 1, Batch: 22, Loss: 31.302\n",
      "Epoch: 1, Batch: 23, Loss: 31.177\n",
      "Epoch: 1, Batch: 24, Loss: 31.266\n",
      "Epoch: 1, Batch: 25, Loss: 31.450\n",
      "Epoch: 1, Batch: 26, Loss: 30.898\n",
      "Epoch: 1, Batch: 27, Loss: 30.972\n",
      "Epoch: 1, Batch: 28, Loss: 31.045\n",
      "Epoch: 1, Batch: 29, Loss: 31.159\n",
      "Epoch: 1, Batch: 30, Loss: 30.893\n",
      "Epoch: 1, Batch: 31, Loss: 31.516\n",
      "Epoch: 1, Batch: 32, Loss: 30.989\n",
      "Epoch: 1, Batch: 33, Loss: 31.348\n",
      "Epoch: 1, Batch: 34, Loss: 30.953\n",
      "Epoch: 1, Batch: 35, Loss: 30.684\n",
      "Epoch: 1, Batch: 36, Loss: 30.322\n",
      "Epoch: 1, Batch: 37, Loss: 30.628\n",
      "Epoch: 1, Batch: 38, Loss: 30.623\n",
      "Epoch: 1, Batch: 39, Loss: 30.405\n",
      "Epoch: 1, Batch: 40, Loss: 30.754\n",
      "Epoch: 1, Batch: 41, Loss: 30.544\n",
      "Epoch: 1, Batch: 42, Loss: 30.712\n",
      "Epoch: 1, Batch: 43, Loss: 30.378\n",
      "Epoch: 1, Batch: 44, Loss: 31.157\n",
      "Epoch: 1, Batch: 45, Loss: 29.926\n",
      "Epoch: 1, Batch: 46, Loss: 30.083\n",
      "Epoch: 1, Batch: 47, Loss: 29.988\n",
      "Epoch: 1, Batch: 48, Loss: 30.256\n",
      "Epoch: 1, Batch: 49, Loss: 30.472\n",
      "Epoch: 1, Batch: 50, Loss: 30.424\n",
      "Epoch: 1, Batch: 51, Loss: 30.149\n",
      "Epoch: 1, Batch: 52, Loss: 29.963\n",
      "Epoch: 1, Batch: 53, Loss: 29.832\n",
      "Epoch: 1, Batch: 54, Loss: 30.152\n",
      "Epoch: 1, Batch: 55, Loss: 29.719\n",
      "Epoch: 1, Batch: 56, Loss: 30.116\n",
      "Epoch: 1, Batch: 57, Loss: 30.071\n",
      "Epoch: 1, Batch: 58, Loss: 29.986\n",
      "Epoch: 1, Batch: 59, Loss: 29.645\n",
      "Epoch: 1, Batch: 60, Loss: 29.519\n",
      "Epoch: 1, Batch: 61, Loss: 29.682\n",
      "Epoch: 1, Batch: 62, Loss: 29.863\n",
      "Epoch: 1, Batch: 63, Loss: 29.360\n",
      "Epoch: 1, Batch: 64, Loss: 30.010\n",
      "Epoch: 1, Batch: 65, Loss: 28.958\n",
      "Epoch: 1, Batch: 66, Loss: 29.680\n",
      "Epoch: 1, Batch: 67, Loss: 29.465\n",
      "Epoch: 1, Batch: 68, Loss: 29.134\n",
      "Epoch: 1, Batch: 69, Loss: 29.526\n",
      "Epoch: 1, Batch: 70, Loss: 28.744\n",
      "Epoch: 1, Batch: 71, Loss: 29.221\n",
      "Epoch: 1, Batch: 72, Loss: 29.361\n",
      "Epoch: 1, Batch: 73, Loss: 28.975\n",
      "Epoch: 1, Batch: 74, Loss: 29.622\n",
      "Epoch: 1, Batch: 75, Loss: 28.496\n",
      "Epoch: 1, Batch: 76, Loss: 29.320\n",
      "Epoch: 1, Batch: 77, Loss: 28.803\n",
      "Epoch: 1, Batch: 78, Loss: 28.467\n",
      "Epoch: 1, Batch: 79, Loss: 28.894\n",
      "Epoch: 1, Batch: 80, Loss: 28.977\n",
      "Epoch: 1, Batch: 81, Loss: 28.635\n",
      "Epoch: 1, Batch: 82, Loss: 28.059\n",
      "Epoch: 1, Batch: 83, Loss: 28.507\n",
      "Epoch: 1, Batch: 84, Loss: 28.262\n",
      "Epoch: 1, Batch: 85, Loss: 28.418\n",
      "Epoch: 1, Batch: 86, Loss: 29.210\n",
      "Epoch: 1, Batch: 87, Loss: 28.751\n",
      "Epoch: 1, Batch: 88, Loss: 29.404\n",
      "Epoch: 1, Batch: 89, Loss: 28.860\n",
      "Epoch: 1, Batch: 90, Loss: 28.113\n",
      "Epoch: 1, Batch: 91, Loss: 29.236\n",
      "Epoch: 1, Batch: 92, Loss: 29.074\n",
      "Epoch: 1, Batch: 93, Loss: 28.092\n",
      "Epoch: 1, Batch: 94, Loss: 27.684\n",
      "Epoch: 1, Batch: 95, Loss: 28.512\n",
      "Epoch: 1, Batch: 96, Loss: 28.626\n",
      "Epoch: 1, Batch: 97, Loss: 28.464\n",
      "Epoch: 1, Batch: 98, Loss: 28.071\n",
      "Epoch: 1, Batch: 99, Loss: 27.792\n",
      "Epoch: 1, Batch: 100, Loss: 27.828\n",
      "Epoch: 1, Batch: 101, Loss: 28.081\n",
      "Epoch: 1, Batch: 102, Loss: 28.912\n",
      "Epoch: 1, Batch: 103, Loss: 28.637\n",
      "Epoch: 1, Batch: 104, Loss: 27.771\n",
      "Epoch: 1, Batch: 105, Loss: 27.891\n",
      "Epoch: 1, Batch: 106, Loss: 27.508\n",
      "Epoch: 1, Batch: 107, Loss: 28.284\n",
      "Epoch: 1, Batch: 108, Loss: 28.025\n",
      "Epoch: 1, Batch: 109, Loss: 27.470\n",
      "Epoch: 1, Batch: 110, Loss: 27.485\n",
      "Epoch: 1, Batch: 111, Loss: 27.211\n",
      "Epoch: 1, Batch: 112, Loss: 27.245\n",
      "Epoch: 1, Batch: 113, Loss: 28.017\n",
      "Epoch: 1, Batch: 114, Loss: 26.780\n",
      "Epoch: 1, Batch: 115, Loss: 27.179\n",
      "Epoch: 1, Batch: 116, Loss: 27.908\n",
      "Epoch: 1, Batch: 117, Loss: 28.178\n",
      "Epoch: 1, Batch: 118, Loss: 27.807\n",
      "Epoch: 1, Batch: 119, Loss: 27.439\n",
      "Epoch: 1, Batch: 120, Loss: 27.975\n",
      "Epoch: 1, Batch: 121, Loss: 27.097\n",
      "Epoch: 1, Batch: 122, Loss: 27.541\n",
      "Epoch: 1, Batch: 123, Loss: 26.510\n",
      "Epoch: 1, Batch: 124, Loss: 28.160\n",
      "Epoch: 1, Batch: 125, Loss: 27.803\n",
      "Epoch: 1, Batch: 126, Loss: 27.392\n",
      "Epoch: 1, Batch: 127, Loss: 28.075\n",
      "Epoch: 1, Batch: 128, Loss: 27.874\n",
      "Epoch: 1, Batch: 129, Loss: 27.700\n",
      "Epoch: 1, Batch: 130, Loss: 26.900\n",
      "Epoch: 1, Batch: 131, Loss: 26.413\n",
      "Epoch: 1, Batch: 132, Loss: 27.584\n",
      "Epoch: 1, Batch: 133, Loss: 27.274\n",
      "Epoch: 1, Batch: 134, Loss: 27.432\n",
      "Epoch: 1, Batch: 135, Loss: 26.522\n",
      "Epoch: 1, Batch: 136, Loss: 27.495\n",
      "Epoch: 1, Batch: 137, Loss: 27.537\n",
      "Epoch: 1, Batch: 138, Loss: 27.173\n",
      "Epoch: 1, Batch: 139, Loss: 26.940\n",
      "Epoch: 1, Batch: 140, Loss: 28.718\n",
      "Epoch: 1, Batch: 141, Loss: 26.106\n",
      "Epoch: 1, Batch: 142, Loss: 27.132\n",
      "Epoch: 1, Batch: 143, Loss: 26.923\n",
      "Epoch: 1, Batch: 144, Loss: 27.242\n",
      "Epoch: 1, Batch: 145, Loss: 26.809\n",
      "Epoch: 1, Batch: 146, Loss: 26.416\n",
      "Epoch: 1, Batch: 147, Loss: 26.785\n",
      "Epoch: 1, Batch: 148, Loss: 26.182\n",
      "Epoch: 1, Batch: 149, Loss: 26.680\n",
      "Epoch: 1, Batch: 150, Loss: 26.056\n",
      "Epoch: 1, Batch: 151, Loss: 26.039\n",
      "Epoch: 1, Batch: 152, Loss: 25.567\n",
      "Epoch: 1, Batch: 153, Loss: 27.310\n",
      "Epoch: 1, Batch: 154, Loss: 26.247\n",
      "Epoch: 1, Batch: 155, Loss: 27.517\n",
      "Epoch: 1, Batch: 156, Loss: 26.626\n",
      "Epoch: 1, Batch: 157, Loss: 26.906\n",
      "Epoch: 2, Batch: 1, Loss: 26.746\n",
      "Epoch: 2, Batch: 2, Loss: 26.995\n",
      "Epoch: 2, Batch: 3, Loss: 25.587\n",
      "Epoch: 2, Batch: 4, Loss: 25.797\n",
      "Epoch: 2, Batch: 5, Loss: 26.285\n",
      "Epoch: 2, Batch: 6, Loss: 26.644\n",
      "Epoch: 2, Batch: 7, Loss: 26.668\n",
      "Epoch: 2, Batch: 8, Loss: 26.346\n",
      "Epoch: 2, Batch: 9, Loss: 25.467\n",
      "Epoch: 2, Batch: 10, Loss: 26.692\n",
      "Epoch: 2, Batch: 11, Loss: 25.844\n",
      "Epoch: 2, Batch: 12, Loss: 26.490\n",
      "Epoch: 2, Batch: 13, Loss: 25.831\n",
      "Epoch: 2, Batch: 14, Loss: 26.342\n",
      "Epoch: 2, Batch: 15, Loss: 26.548\n",
      "Epoch: 2, Batch: 16, Loss: 24.962\n",
      "Epoch: 2, Batch: 17, Loss: 25.508\n",
      "Epoch: 2, Batch: 18, Loss: 25.886\n",
      "Epoch: 2, Batch: 19, Loss: 25.737\n",
      "Epoch: 2, Batch: 20, Loss: 25.347\n",
      "Epoch: 2, Batch: 21, Loss: 24.097\n",
      "Epoch: 2, Batch: 22, Loss: 25.579\n",
      "Epoch: 2, Batch: 23, Loss: 24.407\n",
      "Epoch: 2, Batch: 24, Loss: 26.165\n",
      "Epoch: 2, Batch: 25, Loss: 25.953\n",
      "Epoch: 2, Batch: 26, Loss: 25.139\n",
      "Epoch: 2, Batch: 27, Loss: 26.552\n",
      "Epoch: 2, Batch: 28, Loss: 24.397\n",
      "Epoch: 2, Batch: 29, Loss: 24.853\n",
      "Epoch: 2, Batch: 30, Loss: 26.601\n",
      "Epoch: 2, Batch: 31, Loss: 26.115\n",
      "Epoch: 2, Batch: 32, Loss: 25.577\n",
      "Epoch: 2, Batch: 33, Loss: 26.510\n",
      "Epoch: 2, Batch: 34, Loss: 24.677\n",
      "Epoch: 2, Batch: 35, Loss: 25.398\n",
      "Epoch: 2, Batch: 36, Loss: 26.175\n",
      "Epoch: 2, Batch: 37, Loss: 25.933\n",
      "Epoch: 2, Batch: 38, Loss: 26.117\n",
      "Epoch: 2, Batch: 39, Loss: 23.828\n",
      "Epoch: 2, Batch: 40, Loss: 24.626\n",
      "Epoch: 2, Batch: 41, Loss: 25.203\n",
      "Epoch: 2, Batch: 42, Loss: 24.910\n",
      "Epoch: 2, Batch: 43, Loss: 25.369\n",
      "Epoch: 2, Batch: 44, Loss: 24.965\n",
      "Epoch: 2, Batch: 45, Loss: 24.572\n",
      "Epoch: 2, Batch: 46, Loss: 26.015\n",
      "Epoch: 2, Batch: 47, Loss: 26.047\n",
      "Epoch: 2, Batch: 48, Loss: 25.366\n",
      "Epoch: 2, Batch: 49, Loss: 25.580\n",
      "Epoch: 2, Batch: 50, Loss: 25.189\n",
      "Epoch: 2, Batch: 51, Loss: 24.341\n",
      "Epoch: 2, Batch: 52, Loss: 25.907\n",
      "Epoch: 2, Batch: 53, Loss: 26.793\n",
      "Epoch: 2, Batch: 54, Loss: 24.352\n",
      "Epoch: 2, Batch: 55, Loss: 25.645\n",
      "Epoch: 2, Batch: 56, Loss: 25.027\n",
      "Epoch: 2, Batch: 57, Loss: 25.029\n",
      "Epoch: 2, Batch: 58, Loss: 24.803\n",
      "Epoch: 2, Batch: 59, Loss: 25.763\n",
      "Epoch: 2, Batch: 60, Loss: 25.237\n",
      "Epoch: 2, Batch: 61, Loss: 26.026\n",
      "Epoch: 2, Batch: 62, Loss: 24.448\n",
      "Epoch: 2, Batch: 63, Loss: 25.926\n",
      "Epoch: 2, Batch: 64, Loss: 24.772\n",
      "Epoch: 2, Batch: 65, Loss: 25.187\n",
      "Epoch: 2, Batch: 66, Loss: 23.932\n",
      "Epoch: 2, Batch: 67, Loss: 25.073\n",
      "Epoch: 2, Batch: 68, Loss: 25.442\n",
      "Epoch: 2, Batch: 69, Loss: 25.832\n",
      "Epoch: 2, Batch: 70, Loss: 25.599\n",
      "Epoch: 2, Batch: 71, Loss: 24.977\n",
      "Epoch: 2, Batch: 72, Loss: 25.270\n",
      "Epoch: 2, Batch: 73, Loss: 26.275\n",
      "Epoch: 2, Batch: 74, Loss: 24.747\n",
      "Epoch: 2, Batch: 75, Loss: 25.441\n",
      "Epoch: 2, Batch: 76, Loss: 26.357\n",
      "Epoch: 2, Batch: 77, Loss: 24.808\n",
      "Epoch: 2, Batch: 78, Loss: 24.563\n",
      "Epoch: 2, Batch: 79, Loss: 24.909\n",
      "Epoch: 2, Batch: 80, Loss: 25.285\n",
      "Epoch: 2, Batch: 81, Loss: 24.540\n",
      "Epoch: 2, Batch: 82, Loss: 23.950\n",
      "Epoch: 2, Batch: 83, Loss: 26.461\n",
      "Epoch: 2, Batch: 84, Loss: 25.451\n",
      "Epoch: 2, Batch: 85, Loss: 23.400\n",
      "Epoch: 2, Batch: 86, Loss: 24.329\n",
      "Epoch: 2, Batch: 87, Loss: 24.909\n",
      "Epoch: 2, Batch: 88, Loss: 24.136\n",
      "Epoch: 2, Batch: 89, Loss: 25.082\n",
      "Epoch: 2, Batch: 90, Loss: 25.045\n",
      "Epoch: 2, Batch: 91, Loss: 24.263\n",
      "Epoch: 2, Batch: 92, Loss: 24.292\n",
      "Epoch: 2, Batch: 93, Loss: 24.576\n",
      "Epoch: 2, Batch: 94, Loss: 24.547\n",
      "Epoch: 2, Batch: 95, Loss: 26.176\n",
      "Epoch: 2, Batch: 96, Loss: 24.464\n",
      "Epoch: 2, Batch: 97, Loss: 25.221\n",
      "Epoch: 2, Batch: 98, Loss: 25.050\n",
      "Epoch: 2, Batch: 99, Loss: 25.798\n",
      "Epoch: 2, Batch: 100, Loss: 25.701\n",
      "Epoch: 2, Batch: 101, Loss: 24.435\n",
      "Epoch: 2, Batch: 102, Loss: 23.394\n",
      "Epoch: 2, Batch: 103, Loss: 25.732\n",
      "Epoch: 2, Batch: 104, Loss: 24.010\n",
      "Epoch: 2, Batch: 105, Loss: 24.373\n",
      "Epoch: 2, Batch: 106, Loss: 24.450\n",
      "Epoch: 2, Batch: 107, Loss: 25.024\n",
      "Epoch: 2, Batch: 108, Loss: 25.527\n",
      "Epoch: 2, Batch: 109, Loss: 24.340\n",
      "Epoch: 2, Batch: 110, Loss: 25.260\n",
      "Epoch: 2, Batch: 111, Loss: 25.085\n",
      "Epoch: 2, Batch: 112, Loss: 24.149\n",
      "Epoch: 2, Batch: 113, Loss: 24.355\n",
      "Epoch: 2, Batch: 114, Loss: 24.853\n",
      "Epoch: 2, Batch: 115, Loss: 24.063\n",
      "Epoch: 2, Batch: 116, Loss: 25.507\n",
      "Epoch: 2, Batch: 117, Loss: 24.096\n",
      "Epoch: 2, Batch: 118, Loss: 24.627\n",
      "Epoch: 2, Batch: 119, Loss: 25.677\n",
      "Epoch: 2, Batch: 120, Loss: 24.634\n",
      "Epoch: 2, Batch: 121, Loss: 24.296\n",
      "Epoch: 2, Batch: 122, Loss: 23.656\n",
      "Epoch: 2, Batch: 123, Loss: 24.313\n",
      "Epoch: 2, Batch: 124, Loss: 24.721\n",
      "Epoch: 2, Batch: 125, Loss: 25.035\n",
      "Epoch: 2, Batch: 126, Loss: 23.684\n",
      "Epoch: 2, Batch: 127, Loss: 24.106\n",
      "Epoch: 2, Batch: 128, Loss: 25.217\n",
      "Epoch: 2, Batch: 129, Loss: 23.744\n",
      "Epoch: 2, Batch: 130, Loss: 24.811\n",
      "Epoch: 2, Batch: 131, Loss: 24.293\n",
      "Epoch: 2, Batch: 132, Loss: 24.806\n",
      "Epoch: 2, Batch: 133, Loss: 22.920\n",
      "Epoch: 2, Batch: 134, Loss: 24.690\n",
      "Epoch: 2, Batch: 135, Loss: 24.042\n",
      "Epoch: 2, Batch: 136, Loss: 23.607\n",
      "Epoch: 2, Batch: 137, Loss: 24.754\n",
      "Epoch: 2, Batch: 138, Loss: 23.281\n",
      "Epoch: 2, Batch: 139, Loss: 24.780\n",
      "Epoch: 2, Batch: 140, Loss: 24.048\n",
      "Epoch: 2, Batch: 141, Loss: 24.292\n",
      "Epoch: 2, Batch: 142, Loss: 23.551\n",
      "Epoch: 2, Batch: 143, Loss: 24.134\n",
      "Epoch: 2, Batch: 144, Loss: 24.588\n",
      "Epoch: 2, Batch: 145, Loss: 24.659\n",
      "Epoch: 2, Batch: 146, Loss: 24.306\n",
      "Epoch: 2, Batch: 147, Loss: 25.356\n",
      "Epoch: 2, Batch: 148, Loss: 24.884\n",
      "Epoch: 2, Batch: 149, Loss: 23.886\n",
      "Epoch: 2, Batch: 150, Loss: 24.830\n",
      "Epoch: 2, Batch: 151, Loss: 24.425\n",
      "Epoch: 2, Batch: 152, Loss: 24.008\n",
      "Epoch: 2, Batch: 153, Loss: 23.984\n",
      "Epoch: 2, Batch: 154, Loss: 23.626\n",
      "Epoch: 2, Batch: 155, Loss: 24.345\n",
      "Epoch: 2, Batch: 156, Loss: 24.492\n",
      "Epoch: 2, Batch: 157, Loss: 26.268\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    for i, data in enumerate(zip(*train_loaders)):\n",
    "        running_loss = 0.0\n",
    "        for branch_num, (branch_name, branch_batch) in enumerate(zip(branches, data)):\n",
    "\n",
    "            images, labels = branch_batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = baseline(images, branch_name)\n",
    "\n",
    "            # backward\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # if branch_num == 19:\n",
    "            #     print('Went through all branches')\n",
    "\n",
    "        print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(baseline.state_dict(), os.path.join(Path(os.path.abspath('')).parent, 'models', 'baseline_trained_2_epochs_cifar100.pth'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cd7c2e683202aa99c6bd22cb91ca768a1d33a054ff7cab7f64305a39e1a247d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
